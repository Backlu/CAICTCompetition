{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAICT 風機結冰預測 - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017/07/12  \n",
    "http://www.industrial-bigdata.com/competition/competitionAction!showDetail.action?competition.competitionId=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Load Data and Modules**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Python modules:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import lzma\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import shutil\n",
    "import csv\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from pylab import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateProgress(msg):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def myscore(true_y, pred_y):\n",
    "    n,p =sk.metrics.confusion_matrix(true_y, pred_y)\n",
    "    tn = n[0]\n",
    "    fp = n[1]\n",
    "    fn = p[0]\n",
    "    tp = p[1]\n",
    "    #print('tn:',tn,'fp:',fp,'fn:',fn,'fp:',fp)\n",
    "    score = 1- 0.5*(fp/(tn+fp))- 0.5*(fn/(fn+tp)) \n",
    "    #print('score',score)\n",
    "    return score, {'tn':tn,'fp':fp,'fn':fn,'tp':tp}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StandardScaler(data):\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    data_scaled = standard_scaler.fit_transform(data)\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns = data.columns)\n",
    "    return data_scaled\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    standard_scaler = preprocessing.MinMaxScaler()\n",
    "    data_scaled = standard_scaler.fit_transform(data)\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns = data.columns)\n",
    "    return data_scaled\n",
    "\n",
    "\n",
    "\n",
    "##------------------------\n",
    "\n",
    "def load_resample_data(mid, policy=1,  ycol='power', fillna=0):\n",
    "    filename = 'data/resample_data_p{POLICY}_{ID}.csv'.format(ID=mid,POLICY=policy)\n",
    "    print('load file:',filename)\n",
    "    data_resample = pd.read_csv(filename)\n",
    "    data_resample['label']=data_resample['label'].fillna(fillna)\n",
    "    data_resample[data_resample['label']==2]=0\n",
    "    data_X = data_resample.drop(['label','time','group','timestamp','event'], axis=1)\n",
    "    #data_Y = np.eye(data_y.unique().size)[data_y.values.astype(int)]\n",
    "    non_data_cols = ['label','time','group','timestamp','event']\n",
    "    data_scaled = MinMaxScaler(data_X)\n",
    "    for col in non_data_cols:\n",
    "        data_scaled[col] = data_resample[col]\n",
    "    return data_resample,data_scaled\n",
    "\n",
    "##------------------------\n",
    "\n",
    "def load_test2_data():\n",
    "    test_data = pd.read_csv('data/ice1/test/08/08_data.csv')\n",
    "    test_timeidx = test_data['time']\n",
    "    tmp = test_data.drop(['time','group','generator_speed'], axis=1)\n",
    "    test_X = tmp.values\n",
    "    return test_X, test_timeidx\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_dataset(data, n_steps):\n",
    "    dataset_new = []\n",
    "    for idx, _ in enumerate(data):\n",
    "        start_idx = idx-n_steps\n",
    "        end_idx = idx+1\n",
    "        if start_idx<0:\n",
    "            continue\n",
    "        n=np.concatenate(data[start_idx:end_idx], axis=0)\n",
    "        dataset_new.append(n)\n",
    "    dataset_new = np.asarray(dataset_new)\n",
    "    return dataset_new\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load input data.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xcols=['wind_speed', 'wind_direction',\n",
    "       'wind_direction_mean', 'yaw_position', 'yaw_speed', 'pitch1_angle',\n",
    "       'pitch2_angle', 'pitch3_angle', 'pitch1_speed', 'pitch2_speed',\n",
    "       'pitch3_speed', 'pitch1_moto_tmp', 'pitch2_moto_tmp', 'pitch3_moto_tmp',\n",
    "       'acc_x', 'acc_y', 'environment_tmp', 'int_tmp', 'pitch1_ng5_tmp',\n",
    "       'pitch2_ng5_tmp', 'pitch3_ng5_tmp', 'pitch1_ng5_DC', 'pitch2_ng5_DC',\n",
    "       'pitch3_ng5_DC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file: data/resample_data_p4_15.csv\n",
      "load file: data/resample_data_p0_21.csv\n"
     ]
    }
   ],
   "source": [
    "_, data_scaled_M15 = load_resample_data(mid=15,policy=4)\n",
    "\n",
    "data_M15_train = data_scaled_M15[data_scaled_M15['event']<20]\n",
    "data_M15_valid = data_scaled_M15[data_scaled_M15['event']>=20]\n",
    "\n",
    "ycol='label'\n",
    "data_M15_train_X = data_M15_train[xcols]\n",
    "data_M15_train_y = data_M15_train[ycol]\n",
    "data_M15_train_Y = np.eye(data_M15_train_y.unique().size)[data_M15_train_y.values.astype(int)]\n",
    "\n",
    "data_M15_valid_X = data_M15_valid[xcols]\n",
    "data_M15_valid_y = data_M15_valid[ycol]\n",
    "data_M15_valid_Y = np.eye(data_M15_valid_y.unique().size)[data_M15_valid_y.values.astype(int)]\n",
    "\n",
    "\n",
    "_, data_scaled_M21 = load_resample_data(mid=21,policy=0)\n",
    "data_M21_test_X = data_scaled_M21[xcols]\n",
    "data_M21_test_y = data_scaled_M21[ycol]\n",
    "data_M21_test_Y = np.eye(data_M21_test_y.unique().size)[data_M21_test_y.values.astype(int)]\n",
    "\n",
    "\n",
    "#_, data_X_M21, data_Y_M21, data_y_M21  = load_training_data(mid=21,policy=0)\n",
    "\n",
    "#_, data_X_M21, data_Y_M21, data_y_M21  = load_training_data(mid=21,policy=0)\n",
    "#test_X,test_timeidx = load_test2_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 為了RNN需求, 更改X format **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "n_steps_=n_steps-1\n",
    "data_M15_train_X_new = rnn_dataset(data_M15_train_X.values,n_steps_)\n",
    "data_M15_valid_X_new = rnn_dataset(data_M15_valid_X.values,n_steps_)\n",
    "data_M21_test_X_new = rnn_dataset(data_M21_test_X.values,n_steps_)\n",
    "#test_X = rnn_dataset(test_X,n_steps_)\n",
    "\n",
    "data_M15_train_X_new = data_M15_train_X_new.reshape([-1, 50, len(xcols)])\n",
    "data_M15_valid_X_new = data_M15_valid_X_new.reshape([-1, 50, len(xcols)])\n",
    "data_M21_test_X_new = data_M21_test_X_new.reshape([-1, 50, len(xcols)])\n",
    "#test_X = test_X.reshape([-1, 50, len(xcols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_M15_train_Y_new=data_M15_train_Y[n_steps_:]\n",
    "data_M15_train_y_new=data_M15_train_y[n_steps_:]\n",
    "data_M15_valid_Y_new=data_M15_valid_Y[n_steps_:]\n",
    "data_M15_valid_y_new=data_M15_valid_y[n_steps_:]\n",
    "data_M21_test_Y_new=data_M21_test_Y[n_steps_:]\n",
    "data_M21_test_y_new=data_M21_test_y[n_steps_:]\n",
    "#test_timeidx_new=test_timeidx[n_steps_:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = Sequential()\n",
    "#model1.add(LSTM(512, input_shape=(50, 25),dropout=0.2, recurrent_dropout=0.2))\n",
    "#model1.add(Dense(2))\n",
    "#model1.add(Activation('softmax'))\n",
    "#optimizer = Adam(lr=0.001)\n",
    "#model1.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(50, input_shape=(50, len(xcols)), return_sequences=True))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(LSTM(100,return_sequences=False))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(2))\n",
    "model1.add(Activation('softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"719pt\" viewBox=\"0.00 0.00 420.00 719.00\" width=\"420pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 715)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-715 416,-715 416,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140200182421488 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140200182421488</title>\n",
       "<polygon fill=\"none\" points=\"48.5,-664.5 48.5,-710.5 363.5,-710.5 363.5,-664.5 48.5,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-683.8\">lstm_28_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"211.5,-664.5 211.5,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"211.5,-687.5 266.5,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"266.5,-664.5 266.5,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315\" y=\"-695.3\">(None, 50, 24)</text>\n",
       "<polyline fill=\"none\" points=\"266.5,-687.5 363.5,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315\" y=\"-672.3\">(None, 50, 24)</text>\n",
       "</g>\n",
       "<!-- 140200182422216 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140200182422216</title>\n",
       "<polygon fill=\"none\" points=\"77.5,-581.5 77.5,-627.5 334.5,-627.5 334.5,-581.5 77.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-600.8\">lstm_28: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-581.5 182.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-604.5 237.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"237.5,-581.5 237.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-612.3\">(None, 50, 24)</text>\n",
       "<polyline fill=\"none\" points=\"237.5,-604.5 334.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-589.3\">(None, 50, 50)</text>\n",
       "</g>\n",
       "<!-- 140200182421488&#45;&gt;140200182422216 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140200182421488-&gt;140200182422216</title>\n",
       "<path d=\"M206,-664.366C206,-656.152 206,-646.658 206,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209.5,-637.607 206,-627.607 202.5,-637.607 209.5,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140200182422104 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140200182422104</title>\n",
       "<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 412,-544.5 412,-498.5 0,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-517.8\">batch_normalization_9: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"260,-498.5 260,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"260,-521.5 315,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"315,-498.5 315,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363.5\" y=\"-529.3\">(None, 50, 50)</text>\n",
       "<polyline fill=\"none\" points=\"315,-521.5 412,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363.5\" y=\"-506.3\">(None, 50, 50)</text>\n",
       "</g>\n",
       "<!-- 140200182422216&#45;&gt;140200182422104 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140200182422216-&gt;140200182422104</title>\n",
       "<path d=\"M206,-581.366C206,-573.152 206,-563.658 206,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209.5,-554.607 206,-544.607 202.5,-554.607 209.5,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140200182421432 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140200182421432</title>\n",
       "<polygon fill=\"none\" points=\"64.5,-415.5 64.5,-461.5 347.5,-461.5 347.5,-415.5 64.5,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-434.8\">dropout_17: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"195.5,-415.5 195.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"195.5,-438.5 250.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"250.5,-415.5 250.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299\" y=\"-446.3\">(None, 50, 50)</text>\n",
       "<polyline fill=\"none\" points=\"250.5,-438.5 347.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299\" y=\"-423.3\">(None, 50, 50)</text>\n",
       "</g>\n",
       "<!-- 140200182422104&#45;&gt;140200182421432 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140200182422104-&gt;140200182421432</title>\n",
       "<path d=\"M206,-498.366C206,-490.152 206,-480.658 206,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209.5,-471.607 206,-461.607 202.5,-471.607 209.5,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140200164354704 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140200164354704</title>\n",
       "<polygon fill=\"none\" points=\"77.5,-332.5 77.5,-378.5 334.5,-378.5 334.5,-332.5 77.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-351.8\">lstm_29: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-332.5 182.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-355.5 237.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"237.5,-332.5 237.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-363.3\">(None, 50, 50)</text>\n",
       "<polyline fill=\"none\" points=\"237.5,-355.5 334.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-340.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140200182421432&#45;&gt;140200164354704 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140200182421432-&gt;140200164354704</title>\n",
       "<path d=\"M206,-415.366C206,-407.152 206,-397.658 206,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209.5,-388.607 206,-378.607 202.5,-388.607 209.5,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140200163262192 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140200163262192</title>\n",
       "<polygon fill=\"none\" points=\"4,-249.5 4,-295.5 408,-295.5 408,-249.5 4,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-268.8\">batch_normalization_10: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"270,-249.5 270,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"270,-272.5 325,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"325,-249.5 325,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366.5\" y=\"-280.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"325,-272.5 408,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366.5\" y=\"-257.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140200164354704&#45;&gt;140200163262192 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140200164354704-&gt;140200163262192</title>\n",
       "<path d=\"M206,-332.366C206,-324.152 206,-314.658 206,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209.5,-305.607 206,-295.607 202.5,-305.607 209.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140200162374712 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140200162374712</title>\n",
       "<polygon fill=\"none\" points=\"71.5,-166.5 71.5,-212.5 340.5,-212.5 340.5,-166.5 71.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-185.8\">dropout_18: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"202.5,-166.5 202.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"202.5,-189.5 257.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"257.5,-166.5 257.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299\" y=\"-197.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"257.5,-189.5 340.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299\" y=\"-174.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140200163262192&#45;&gt;140200162374712 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140200163262192-&gt;140200162374712</title>\n",
       "<path d=\"M206,-249.366C206,-241.152 206,-231.658 206,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209.5,-222.607 206,-212.607 202.5,-222.607 209.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140200160819800 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140200160819800</title>\n",
       "<polygon fill=\"none\" points=\"82.5,-83.5 82.5,-129.5 329.5,-129.5 329.5,-83.5 82.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-102.8\">dense_18: Dense</text>\n",
       "<polyline fill=\"none\" points=\"191.5,-83.5 191.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"191.5,-106.5 246.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"246.5,-83.5 246.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-114.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"246.5,-106.5 329.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-91.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140200162374712&#45;&gt;140200160819800 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140200162374712-&gt;140200160819800</title>\n",
       "<path d=\"M206,-166.366C206,-158.152 206,-148.658 206,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209.5,-139.607 206,-129.607 202.5,-139.607 209.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140200160818064 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140200160818064</title>\n",
       "<polygon fill=\"none\" points=\"66.5,-0.5 66.5,-46.5 345.5,-46.5 345.5,-0.5 66.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"144\" y=\"-19.8\">activation_18: Activation</text>\n",
       "<polyline fill=\"none\" points=\"221.5,-0.5 221.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"221.5,-23.5 276.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"276.5,-0.5 276.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-31.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"276.5,-23.5 345.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-8.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140200160819800&#45;&gt;140200160818064 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140200160819800-&gt;140200160818064</title>\n",
       "<path d=\"M206,-83.3664C206,-75.1516 206,-65.6579 206,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209.5,-56.6068 206,-46.6068 202.5,-56.6069 209.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model1, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30000/78307 [==========>...................] - ETA: 8s - loss: 0.0128"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-cd59f722b6c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_M15_train_X_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_M15_train_Y_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bigdata/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1.fit(data_M15_train_X_new, data_M15_train_Y_new, batch_size=500, epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4. 預測與準確率評估  Evaluation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78356,)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_M15_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32518\n",
       "1    23671\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    54502\n",
       "1    23805\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.980592312539\n",
      "Recall 0.986143382198\n",
      "score 0.988843709548 {'tn': 54174, 'fp': 462, 'fn': 328, 'tp': 23343}\n"
     ]
    }
   ],
   "source": [
    "ret = model1.predict(data_M15_train_X_new)\n",
    "pred_t = pd.DataFrame(ret)\n",
    "pred_t = pred_t.apply(np.argmax,axis=1)\n",
    "pd.Series(data_M15_train_y_new).value_counts()\n",
    "pred_t.value_counts()\n",
    "print(\"Precision\", precision_score(data_M15_train_y_new, pred_t))\n",
    "print(\"Recall\", sk.metrics.recall_score(data_M15_train_y_new, pred_t))\n",
    "\n",
    "s,_=myscore(data_M15_train_y_new, pred_t)\n",
    "print('score',s,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8586\n",
       "1    4310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1    8599\n",
       "0    4297\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.390394231887\n",
      "Recall 0.778886310905\n",
      "score 0.584178771572 {'tn': 3344, 'fp': 5242, 'fn': 953, 'tp': 3357}\n"
     ]
    }
   ],
   "source": [
    "ret = model1.predict(data_M15_valid_X_new)\n",
    "pred_t = pd.DataFrame(ret)\n",
    "pred_t = pred_t.apply(np.argmax,axis=1)\n",
    "pd.Series(data_M15_valid_y_new).value_counts()\n",
    "pred_t.value_counts()\n",
    "print(\"Precision\", precision_score(data_M15_valid_y_new, pred_t))\n",
    "print(\"Recall\", sk.metrics.recall_score(data_M15_valid_y_new, pred_t))\n",
    "\n",
    "s,_=myscore(data_M15_valid_y_new, pred_t)\n",
    "print('score',s,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8586\n",
       "1    4310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1    99899\n",
       "0    90546\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.0877185957817\n",
      "Recall 0.823745064862\n",
      "score 0.658445246508 {'tn': 88671, 'fp': 91136, 'fn': 1875, 'tp': 8763}\n"
     ]
    }
   ],
   "source": [
    "ret = model1.predict(data_M21_test_X_new)\n",
    "pred_t = pd.DataFrame(ret)\n",
    "pred_t = pred_t.apply(np.argmax,axis=1)\n",
    "pd.Series(data_M21_test_y_new).value_counts()\n",
    "pred_t.value_counts()\n",
    "print(\"Precision\", precision_score(data_M21_test_y_new, pred_t))\n",
    "print(\"Recall\", sk.metrics.recall_score(data_M21_test_y_new, pred_t))\n",
    "\n",
    "s,_=myscore(data_M21_test_y_new, pred_t)\n",
    "print('score',s,_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X_rs = test_X.reshape([-1, n_steps, n_inputs])\n",
    "test_X_rs__1 = test_X_rs[:100000]\n",
    "pred_T1 = pd.DataFrame(pred.eval({X: test_X_rs__1}))\n",
    "pred_T1 = pred_T1.apply(np.argmax,axis=1)\n",
    "pred_T1.value_counts()\n",
    "\n",
    "test_X_rs__2 = test_X_rs[100000:]\n",
    "pred_T2 = pd.DataFrame(pred.eval({X: test_X_rs__2}))\n",
    "pred_T2 = pred_T2.apply(np.argmax,axis=1)\n",
    "pred_T2.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_T = pred_T1.append(pred_T2)\n",
    "pred_T.shape\n",
    "pred_T.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 整理預測結果, 正確上傳格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startTime=0\n",
    "endTIme=0\n",
    "search_start=True\n",
    "search_end=False\n",
    "abnormal_list=[]\n",
    "shift = test_timeidx_new.index[0]\n",
    "for i,v in enumerate(pred_T):\n",
    "    i=i+shift\n",
    "    if (v==1) & (search_start):\n",
    "        startTime = test_timeidx_new[i]\n",
    "        search_end=True\n",
    "        search_start=False\n",
    "    if (v==0) & (search_end):\n",
    "        endTIme=test_timeidx_new[i]\n",
    "        search_start=True\n",
    "        search_end=False\n",
    "        abnormal_list.append((startTime,test_timeidx_new[i-1]))\n",
    "len(abnormal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_ans=True\n",
    "if(output_ans):\n",
    "    with open('test1_08_results.csv','w') as out:\n",
    "        csv_out=csv.writer(out)\n",
    "        csv_out.writerow(['startTime','endTime'])\n",
    "        for row in abnormal_list:\n",
    "            dummy = csv_out.writerow(row)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abnormal_list[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Issue\n",
    "1. Data Imbalance\n",
    " - training batch sample 一半normal一半abnormal的data\n",
    " - 用兩台風機訓練兩個model, 取故障預測的聯集 \n",
    "\n",
    "2. 用Precision & Recall評估好壞, 算出Score\n",
    "\n",
    "\n",
    "other:\n",
    "- using weighted examples. Just amplify the per-instance loss by a larger weight when seeing positive examples. If you use online gradient descent, it can be as simple as using a larger learning rate when seeing positive examples.\n",
    "- A similar and slightly better approach (only if you use stochastic gradient descent) is randomly picking an example in each iteration, where the positive examples have higher probability of being picked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "提交结果历史记录  \n",
    "参赛队伍:　556 / 参赛人数:　858  \n",
    " \n",
    "|竞赛阶段\t |上传者\t |分数\t |提交日期\t |排名\t |下载|\n",
    "| ---------| -------- | ------ | ------ | ------ | ------ |\n",
    "|初赛test1阶段|\t孔祥千\t|55.28684214|\t2017/7/12|\t50\t|下载|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 7/13\n",
    "1. cross correlation\n",
    "2. auto correlation\n",
    "3. common filter\n",
    "4. de-train "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
